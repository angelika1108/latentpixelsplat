{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "encoder_init_path = \"/home/angelika/latentpixelsplat/checkpoint_init/encoder_init.pth\"\n",
    "decoder_latent_init_path = \"/home/angelika/latentpixelsplat/checkpoint_init/decoder_latent_init.pth\"\n",
    "\n",
    "encoder_init = torch.load(encoder_init_path, map_location=\"cpu\")\n",
    "decoder_latent_init = torch.load(decoder_latent_init_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "# Loading the original state_dicts of the encoder and the decoder\n",
    "encoder_state_dict = load_file(\"/home/angelika/vae/pretrained_models/taesd_encoder.safetensors\")\n",
    "decoder_state_dict = load_file(\"/home/angelika/vae/pretrained_models/taesd_decoder.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0.bias', '0.weight', '1.conv.0.bias', '1.conv.0.weight', '1.conv.2.bias', '1.conv.2.weight', '1.conv.4.bias', '1.conv.4.weight', '10.bias', '10.weight', '2.weight', '3.conv.0.bias', '3.conv.0.weight', '3.conv.2.bias', '3.conv.2.weight', '3.conv.4.bias', '3.conv.4.weight', '4.conv.0.bias', '4.conv.0.weight', '4.conv.2.bias', '4.conv.2.weight', '4.conv.4.bias', '4.conv.4.weight', '5.conv.0.bias', '5.conv.0.weight', '5.conv.2.bias', '5.conv.2.weight', '5.conv.4.bias', '5.conv.4.weight', '6.weight', '7.conv.0.bias', '7.conv.0.weight', '7.conv.2.bias', '7.conv.2.weight', '7.conv.4.bias', '7.conv.4.weight', '8.conv.0.bias', '8.conv.0.weight', '8.conv.2.bias', '8.conv.2.weight', '8.conv.4.bias', '8.conv.4.weight', '9.conv.0.bias', '9.conv.0.weight', '9.conv.2.bias', '9.conv.2.weight', '9.conv.4.bias', '9.conv.4.weight'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1.bias', '1.weight', '10.conv.0.bias', '10.conv.0.weight', '10.conv.2.bias', '10.conv.2.weight', '10.conv.4.bias', '10.conv.4.weight', '12.weight', '13.conv.0.bias', '13.conv.0.weight', '13.conv.2.bias', '13.conv.2.weight', '13.conv.4.bias', '13.conv.4.weight', '14.bias', '14.weight', '3.conv.0.bias', '3.conv.0.weight', '3.conv.2.bias', '3.conv.2.weight', '3.conv.4.bias', '3.conv.4.weight', '4.conv.0.bias', '4.conv.0.weight', '4.conv.2.bias', '4.conv.2.weight', '4.conv.4.bias', '4.conv.4.weight', '5.conv.0.bias', '5.conv.0.weight', '5.conv.2.bias', '5.conv.2.weight', '5.conv.4.bias', '5.conv.4.weight', '7.weight', '8.conv.0.bias', '8.conv.0.weight', '8.conv.2.bias', '8.conv.2.weight', '8.conv.4.bias', '8.conv.4.weight', '9.conv.0.bias', '9.conv.0.weight', '9.conv.2.bias', '9.conv.2.weight', '9.conv.4.bias', '9.conv.4.weight'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in decoder_latent_init.keys():\n",
    "#     print(key)\n",
    "\n",
    "# layers.1.weight\n",
    "# layers.1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latent decoder weights\n",
    "\n",
    "for key in decoder_state_dict.keys():\n",
    "    new_key = 'layers.' + key\n",
    "    decoder_latent_init[new_key] = decoder_state_dict[key]\n",
    "    # print(key, '---', new_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in encoder_init.keys():\n",
    "#     if ('backbone' not in key) and ('epipolar_transformer' not in key) and ('depth_predictor' not in key) and ('to_gaussians' not in key) and ('high_resolution_skip' not in key):\n",
    "#         print(key)\n",
    "\n",
    "# encoder_latent.layers.0.weight\n",
    "# encoder_latent.layers.0.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latent encoder weights\n",
    "\n",
    "for key in encoder_state_dict.keys():\n",
    "    new_key = 'encoder_latent.layers.' + key\n",
    "    encoder_init[new_key] = encoder_state_dict[key]\n",
    "    # print(key, '---', new_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt_path = \"/home/angelika/latentpixelsplat/pretrained_models/encoder_latent_tiny.pth\"\n",
    "# torch.save(encoder_init, new_ckpt_path)\n",
    "\n",
    "new_ckpt = torch.load(new_ckpt_path, map_location=\"cpu\")\n",
    "# for key in new_ckpt.keys():\n",
    "#     if 'backbone' not in key and 'epipolar_transformer' not in key:\n",
    "#         print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt_path = \"/home/angelika/latentpixelsplat/pretrained_models/decoder_latent_tiny.pth\"\n",
    "# torch.save(decoder_latent_init, new_ckpt_path)\n",
    "\n",
    "new_ckpt = torch.load(new_ckpt_path, map_location=\"cpu\")\n",
    "# for key in new_ckpt.keys():\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n",
      "encoder.depth_predictor.projection.1.weight\n",
      "encoder.depth_predictor.projection.1.bias\n",
      "encoder.to_gaussians.1.weight\n",
      "encoder.to_gaussians.1.bias\n",
      "encoder.high_resolution_skip.0.weight\n",
      "encoder.high_resolution_skip.0.bias\n"
     ]
    }
   ],
   "source": [
    "encoder_init_path = \"/home/angelika/latentpixelsplat/checkpoint_init/encoder_init.pth\"\n",
    "encoder_init = torch.load(encoder_init_path, map_location=\"cpu\")\n",
    "\n",
    "\n",
    "ckpt_path = \"/home/angelika/latentpixelsplat/pretrained_models/acid.ckpt\"\n",
    "# ckpt_path = \"/home/angelika/latentpixelsplat/pretrained_models/re10k.ckpt\"\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "print(ckpt.keys())\n",
    "\n",
    "for key in ckpt['state_dict'].keys():\n",
    "    # print(key)\n",
    "    if ('backbone' not in key) and ('epipolar_transformer' not in key):\n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_predictor.projection.1.weight\n",
      "depth_predictor.projection.1.bias\n",
      "to_gaussians.1.weight\n",
      "to_gaussians.1.bias\n",
      "to_gaussians_2.1.weight\n",
      "to_gaussians_2.1.bias\n",
      "high_resolution_skip.0.weight\n",
      "high_resolution_skip.0.bias\n"
     ]
    }
   ],
   "source": [
    "for key in encoder_init.keys():\n",
    "    # print(key)\n",
    "    if ('backbone' not in key) and ('epipolar_transformer' not in key) and ('encoder_latent' not in key):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoder weights\n",
    "\n",
    "for key in encoder_init.keys():\n",
    "    if ('to_gaussians_2' not in key) and ('high_resolution_skip' not in key) and ('encoder_latent' not in key):\n",
    "        ckpt_key = 'encoder.' + key\n",
    "        encoder_init[key] = ckpt['state_dict'][ckpt_key]\n",
    "        # print(key, '---', ckpt_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latent encoder weights\n",
    "load_latent_encoder_weights = False\n",
    "\n",
    "if load_latent_encoder_weights:\n",
    "    for key in encoder_state_dict.keys():\n",
    "        new_key = 'encoder_latent.layers.' + key\n",
    "        encoder_init[new_key] = encoder_state_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84, 128])\n",
      "torch.Size([84])\n",
      "torch.Size([75, 128])\n",
      "torch.Size([75])\n",
      "torch.Size([75, 128])\n"
     ]
    }
   ],
   "source": [
    "print(ckpt['state_dict']['encoder.to_gaussians.1.weight'].shape)\n",
    "print(ckpt['state_dict']['encoder.to_gaussians.1.bias'].shape)\n",
    "print(encoder_init['to_gaussians_2.1.weight'].shape)\n",
    "print(encoder_init['to_gaussians_2.1.bias'].shape)\n",
    "\n",
    "print(ckpt['state_dict']['encoder.to_gaussians.1.weight'][9:, :].shape)\n",
    "\n",
    "encoder_init['to_gaussians_2.1.weight'] = ckpt['state_dict']['encoder.to_gaussians.1.weight'][9:, :]\n",
    "encoder_init['to_gaussians_2.1.bias'] = ckpt['state_dict']['encoder.to_gaussians.1.bias'][9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 7, 7])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 4, 7, 7])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(ckpt['state_dict']['encoder.high_resolution_skip.0.weight'].shape)\n",
    "print(ckpt['state_dict']['encoder.high_resolution_skip.0.bias'].shape)\n",
    "print(encoder_init['high_resolution_skip.0.weight'].shape)\n",
    "print(encoder_init['high_resolution_skip.0.bias'].shape)\n",
    "\n",
    "encoder_init['high_resolution_skip.0.bias'] = ckpt['state_dict']['encoder.high_resolution_skip.0.bias']\n",
    "\n",
    "encoder_init['high_resolution_skip.0.weight'][:, :3, :, :] = ckpt['state_dict']['encoder.high_resolution_skip.0.weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 7, 7])\n",
      "torch.Size([128, 7, 7])\n",
      "torch.Size([128, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "mean = torch.mean(ckpt['state_dict']['encoder.high_resolution_skip.0.weight'], dim=1)\n",
    "print(mean.shape)\n",
    "\n",
    "std = torch.std(ckpt['state_dict']['encoder.high_resolution_skip.0.weight'], dim=1)\n",
    "print(std.shape)\n",
    "\n",
    "n01 = torch.randn(128, 7, 7)\n",
    "latent_ch4 = n01 * std + mean\n",
    "print(latent_ch4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_init['high_resolution_skip.0.weight'][:, 3, :, :] = latent_ch4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_latent_encoder_weights:\n",
    "    new_ckpt_path = \"/home/angelika/latentpixelsplat/pretrained_models/encoder_and_encoder_latent_tiny.pth\"\n",
    "    # torch.save(encoder_init, new_ckpt_path)\n",
    "else:\n",
    "    new_ckpt_path = \"/home/angelika/latentpixelsplat/pretrained_models/encoder_tiny.pth\"\n",
    "    # torch.save(encoder_init, new_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt = torch.load(new_ckpt_path, map_location=\"cpu\")\n",
    "# for key in new_ckpt.keys():\n",
    "#     if 'backbone' not in key and 'epipolar_transformer' not in key:\n",
    "#         print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n"
     ]
    }
   ],
   "source": [
    "# Load pixelsplat_copy encoder weights\n",
    "\n",
    "encoder_init_path = \"/home/angelika/pixelsplat_copy/checkpoint_init/encoder_init.pth\"\n",
    "encoder_init = torch.load(encoder_init_path, map_location=\"cpu\")\n",
    "\n",
    "\n",
    "ckpt_path = \"/home/angelika/pixelsplat_copy/pretrained_models/acid.ckpt\"\n",
    "# ckpt_path = \"/home/angelika/pixelsplat_copy/pretrained_models/re10k.ckpt\"\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "print(ckpt.keys())\n",
    "\n",
    "# for key in ckpt['state_dict'].keys():\n",
    "#     # print(key)\n",
    "#     if ('backbone' not in key) and ('epipolar_transformer' not in key):\n",
    "#         print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoder weights\n",
    "\n",
    "for key in encoder_init.keys():\n",
    "    ckpt_key = 'encoder.' + key\n",
    "    encoder_init[key] = ckpt['state_dict'][ckpt_key]\n",
    "    # print(key, '---', ckpt_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt_path = \"/home/angelika/pixelsplat_copy/pretrained_models/encoder.pth\"\n",
    "# torch.save(encoder_init, new_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c366dd8ba5464256c37f497fa064163cf612104d997efd8106f0db6f2ed53f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
